{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71bde2b1ca7b6f53",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### CartPole\n",
    "##### with Q-learning from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0fb9d0358ad7e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:09:13.164013200Z",
     "start_time": "2023-10-18T20:09:13.139977200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation\n",
    "import threading\n",
    "import pickle\n",
    "import joblib\n",
    "import copy\n",
    "import threading\n",
    "from sklearn import impute, preprocessing, model_selection, base, metrics, linear_model, pipeline, ensemble, svm, multiclass, neighbors, compose, datasets, decomposition, manifold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "from custom_objects import decorators\n",
    "import gym\n",
    "import pygame as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37564b75be5662c0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Environment\n",
    "**Setup the CartPole environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10696c005d35255e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:09:13.706734300Z",
     "start_time": "2023-10-18T20:09:13.685720800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Environment\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "clock = pg.time.Clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6736489489a0e6ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:09:14.529597Z",
     "start_time": "2023-10-18T20:09:13.904330200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdb43cf31d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAGkCAYAAACb5OmoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAo90lEQVR4nO3df3DU9YH/8Vd+kIUAuzFAsokEikrBCMEeaNix9WhJCZj6lZqbUUsl7TFwconfQizV3FBQe2M4elOVDkJ7vRPvTorFKfolFWwECWMJiJEMCMoIwzUo2cTKZDfEsvmx7+8f/fL5dpVfC8nue9nnY+Yzk93PO7vvfcs4z/l8PvtJijHGCAAAAHGXGu8JAAAA4C8IMwAAAEsQZgAAAJYgzAAAACxBmAEAAFiCMAMAALAEYQYAAGAJwgwAAMAShBkAAIAlCDMAAABLJGSYrV27Vl/60pc0ePBgFRcX6+233473lBLW7t27dffddys/P18pKSl65ZVXIvYbY7RixQrl5eVpyJAhKikp0Ycffhgx5vTp05o3b57cbreysrK0YMECnTlzJoafInHU1tbqtttu0/Dhw5WTk6O5c+fq6NGjEWPOnj2ryspKjRgxQsOGDVN5ebna2toixrS0tKisrEyZmZnKycnRsmXL1NvbG8uPkjDWrVunoqIiud1uud1u+Xw+bdu2zdnPeg+8VatWKSUlRUuWLHGeY9371+OPP66UlJSIbeLEic5+1jtxJFyYvfTSS6qurtbKlSv17rvvasqUKSotLVV7e3u8p5aQurq6NGXKFK1du/a8+1evXq01a9Zo/fr12rdvn4YOHarS0lKdPXvWGTNv3jwdPnxY9fX1qqur0+7du7Vo0aJYfYSE0tDQoMrKSu3du1f19fXq6enRrFmz1NXV5YxZunSptm7dqs2bN6uhoUGnTp3Svffe6+zv6+tTWVmZuru7tWfPHr3wwgvasGGDVqxYEY+PZL3Ro0dr1apVampq0jvvvKNvfOMbuueee3T48GFJrPdA279/v37xi1+oqKgo4nnWvf/dcsstam1tdba33nrL2cd6JxCTYG6//XZTWVnpPO7r6zP5+fmmtrY2jrO6NkgyW7ZscR6Hw2Hj9XrNT3/6U+e5jo4O43K5zK9//WtjjDFHjhwxksz+/fudMdu2bTMpKSnm448/jtncE1V7e7uRZBoaGowxf1nfQYMGmc2bNztj3n//fSPJNDY2GmOMee2110xqaqrx+/3OmHXr1hm3221CoVBsP0CCuu6668yvfvUr1nuAdXZ2mvHjx5v6+nrzt3/7t+YHP/iBMYZ/5wNh5cqVZsqUKefdx3onloQ6Ytbd3a2mpiaVlJQ4z6WmpqqkpESNjY1xnNm16cSJE/L7/RHr7fF4VFxc7Kx3Y2OjsrKyNG3aNGdMSUmJUlNTtW/fvpjPOdEEAgFJUnZ2tiSpqalJPT09EWs+ceJEjRkzJmLNJ0+erNzcXGdMaWmpgsGgcxQI59fX16dNmzapq6tLPp+P9R5glZWVKisri1hfiX/nA+XDDz9Ufn6+brjhBs2bN08tLS2SWO9Ekx7vCUTjT3/6k/r6+iL+4UhSbm6uPvjggzjN6trl9/sl6bzrfW6f3+9XTk5OxP709HRlZ2c7Y3B+4XBYS5Ys0R133KFJkyZJ+st6ZmRkKCsrK2Ls59f8fP9Nzu3DFx06dEg+n09nz57VsGHDtGXLFhUWFqq5uZn1HiCbNm3Su+++q/37939hH//O+19xcbE2bNigCRMmqLW1VU888YS+9rWv6b333mO9E0xChRlwLamsrNR7770XcR0IBsaECRPU3NysQCCgl19+WRUVFWpoaIj3tK5ZJ0+e1A9+8APV19dr8ODB8Z5OUpgzZ47zc1FRkYqLizV27Fj95je/0ZAhQ+I4M0QroU5ljhw5UmlpaV/4JklbW5u8Xm+cZnXtOremF1tvr9f7hS9e9Pb26vTp0/w3uYiqqirV1dXpzTff1OjRo53nvV6vuru71dHRETH+82t+vv8m5/bhizIyMnTTTTdp6tSpqq2t1ZQpU/Tss8+y3gOkqalJ7e3t+pu/+Rulp6crPT1dDQ0NWrNmjdLT05Wbm8u6D7CsrCx9+ctf1rFjx/h3nmASKswyMjI0depU7dixw3kuHA5rx44d8vl8cZzZtWncuHHyer0R6x0MBrVv3z5nvX0+nzo6OtTU1OSM2blzp8LhsIqLi2M+Z9sZY1RVVaUtW7Zo586dGjduXMT+qVOnatCgQRFrfvToUbW0tESs+aFDhyKCuL6+Xm63W4WFhbH5IAkuHA4rFAqx3gNk5syZOnTokJqbm51t2rRpmjdvnvMz6z6wzpw5o+PHjysvL49/54km3t8+iNamTZuMy+UyGzZsMEeOHDGLFi0yWVlZEd8kweXr7Ow0Bw4cMAcOHDCSzM9+9jNz4MAB88c//tEYY8yqVatMVlaWefXVV83BgwfNPffcY8aNG2f+/Oc/O68xe/Zs85WvfMXs27fPvPXWW2b8+PHmgQceiNdHstrixYuNx+Mxu3btMq2trc722WefOWMeeughM2bMGLNz507zzjvvGJ/PZ3w+n7O/t7fXTJo0ycyaNcs0Nzeb7du3m1GjRpmampp4fCTrPfbYY6ahocGcOHHCHDx40Dz22GMmJSXF/P73vzfGsN6x8tffyjSGde9vjzzyiNm1a5c5ceKE+cMf/mBKSkrMyJEjTXt7uzGG9U4kCRdmxhjz85//3IwZM8ZkZGSY22+/3ezduzfeU0pYb775ppH0ha2iosIY85dbZvz4xz82ubm5xuVymZkzZ5qjR49GvMann35qHnjgATNs2DDjdrvN97//fdPZ2RmHT2O/8621JPP88887Y/785z+bf/zHfzTXXXedyczMNN/+9rdNa2trxOv8z//8j5kzZ44ZMmSIGTlypHnkkUdMT09PjD9NYvj7v/97M3bsWJORkWFGjRplZs6c6USZMax3rHw+zFj3/nXfffeZvLw8k5GRYa6//npz3333mWPHjjn7We/EkWKMMfE5VgcAAIC/llDXmAEAAFzLCDMAAABLEGYAAACWIMwAAAAsQZgBAABYgjADAACwRMKGWSgU0uOPP65QKBTvqSQN1jz2WPPYY81jjzWPPdbcXgl7H7NgMCiPx6NAICC32x3v6SQF1jz2WPPYY81jjzWPPdbcXnE9YrZ27Vp96Utf0uDBg1VcXKy33347ntMBAACIq7iF2UsvvaTq6mqtXLlS7777rqZMmaLS0tKIP6AKAACQTNLj9cY/+9nPtHDhQn3/+9+XJK1fv16/+93v9B//8R967LHHLvq74XBYH3/8saS/HI5FbJxba9Y8dljz2GPNY481jz3WPLaMMers7FR+fr5SUy9+TCwu15h1d3crMzNTL7/8subOnes8X1FRoY6ODr366qsR40OhUMQFih9//LEKCwtjNV0AAICrdvLkSY0ePfqiY+JyxOxPf/qT+vr6lJubG/F8bm6uPvjggy+Mr62t1RNPPPGF50+ePMlFiwAAwGrBYFAFBQUaPnz4JcfG7VRmNGpqalRdXe08PvcB3W43YQYAABJCSkrKJcfEJcxGjhyptLQ0tbW1RTzf1tYmr9f7hfEul0sulytW0wMAAIiLuHwrMyMjQ1OnTtWOHTuc58LhsHbs2CGfzxePKQEAAMRd3E5lVldXq6KiQtOmTdPtt9+uZ555Rl1dXc63NAEAAJJN3MLsvvvu0yeffKIVK1bI7/fr1ltv1fbt27/whQAAAIBkkZB/kok/JQEAABJFNN2SsH/EHAAA4FpDmAEAAFiCMAMAALAEYQYAAGAJwgwAAMAShBkAAIAlCDMAAABLEGYAAACWIMwAAAAsQZgBAABYgjADAACwBGEGAABgCcIMAADAEoQZAACAJQgzAAAASxBmAAAAliDMAAAALEGYAQAAWIIwAwAAsARhBgAAYAnCDAAAwBKEGQAAgCUIMwAAAEsQZgAAAJYgzAAAACxBmAEAAFiCMAMAALAEYQYAAGAJwgwAAMAShBkAAIAlCDMAAABLEGYAAACWIMwAAAAsQZgBAABYgjADAACwRL+H2eOPP66UlJSIbeLEic7+s2fPqrKyUiNGjNCwYcNUXl6utra2/p4GAABAwhmQI2a33HKLWltbne2tt95y9i1dulRbt27V5s2b1dDQoFOnTunee+8diGkAAAAklPQBedH0dHm93i88HwgE9O///u/auHGjvvGNb0iSnn/+ed18883au3evpk+fPhDTAQAASAgDcsTsww8/VH5+vm644QbNmzdPLS0tkqSmpib19PSopKTEGTtx4kSNGTNGjY2NF3y9UCikYDAYsQEAAFxr+j3MiouLtWHDBm3fvl3r1q3TiRMn9LWvfU2dnZ3y+/3KyMhQVlZWxO/k5ubK7/df8DVra2vl8XicraCgoL+nDQAAEHf9fipzzpw5zs9FRUUqLi7W2LFj9Zvf/EZDhgy5otesqalRdXW18zgYDBJnAADgmjPgt8vIysrSl7/8ZR07dkxer1fd3d3q6OiIGNPW1nbea9LOcblccrvdERsAAMC1ZsDD7MyZMzp+/Ljy8vI0depUDRo0SDt27HD2Hz16VC0tLfL5fAM9FQAAAKv1+6nMH/7wh7r77rs1duxYnTp1SitXrlRaWpoeeOABeTweLViwQNXV1crOzpbb7dbDDz8sn8/HNzIBAEDS6/cw++ijj/TAAw/o008/1ahRo/TVr35Ve/fu1ahRoyRJTz/9tFJTU1VeXq5QKKTS0lI999xz/T0NAACAhJNijDHxnkS0gsGgPB6PAoEA15sBAACrRdMt/K1MAAAASxBmAAAAliDMAAAALEGYAQAAWIIwAwAAsARhBgAAYAnCDAAAwBKEGQAAgCUIMwAAAEsQZgAAAJYgzAAAACxBmAEAAFiCMAMAALAEYQYAAGAJwgwAAMAShBkAAIAlCDMAAABLEGYAAACWIMwAAAAsQZgBAABYgjADAACwBGEGAABgCcIMAADAEoQZAACAJQgzAAAASxBmAAAAliDMAAAALEGYAQAAWIIwAwAAsARhBgAAYAnCDAAAwBKEGQAAgCUIMwAAAEsQZgAAAJYgzAAAACxBmAEAAFgi6jDbvXu37r77buXn5yslJUWvvPJKxH5jjFasWKG8vDwNGTJEJSUl+vDDDyPGnD59WvPmzZPb7VZWVpYWLFigM2fOXNUHAQAASHRRh1lXV5emTJmitWvXnnf/6tWrtWbNGq1fv1779u3T0KFDVVpaqrNnzzpj5s2bp8OHD6u+vl51dXXavXu3Fi1adOWfAgAA4BqQYowxV/zLKSnasmWL5s6dK+kvR8vy8/P1yCOP6Ic//KEkKRAIKDc3Vxs2bND999+v999/X4WFhdq/f7+mTZsmSdq+fbvuuusuffTRR8rPz7/k+waDQXk8HgUCAbnd7iudPgAAwICLplv69RqzEydOyO/3q6SkxHnO4/GouLhYjY2NkqTGxkZlZWU5USZJJSUlSk1N1b59+877uqFQSMFgMGIDAAC41vRrmPn9fklSbm5uxPO5ubnOPr/fr5ycnIj96enpys7OdsZ8Xm1trTwej7MVFBT057QBAACskBDfyqypqVEgEHC2kydPxntKAAAA/a5fw8zr9UqS2traIp5va2tz9nm9XrW3t0fs7+3t1enTp50xn+dyueR2uyM2AACAa02/htm4cePk9Xq1Y8cO57lgMKh9+/bJ5/NJknw+nzo6OtTU1OSM2blzp8LhsIqLi/tzOgAAAAklPdpfOHPmjI4dO+Y8PnHihJqbm5Wdna0xY8ZoyZIl+ud//meNHz9e48aN049//GPl5+c739y8+eabNXv2bC1cuFDr169XT0+PqqqqdP/991/WNzIBAACuVVGH2TvvvKOvf/3rzuPq6mpJUkVFhTZs2KAf/ehH6urq0qJFi9TR0aGvfvWr2r59uwYPHuz8zosvvqiqqirNnDlTqampKi8v15o1a/rh4wAAACSuq7qPWbxwHzMAAJAo4nYfMwAAAFw5wgwAAMAShBkAAIAlCDMAAABLEGYAAACWIMwAAAAsQZgBAABYgjADAACwBGEGAABgCcIMAADAEoQZAACAJQgzAAAASxBmAAAAliDMAAAALEGYAQAAWIIwAwAAsARhBgAAYAnCDAAAwBKEGQAAgCUIMwAAAEsQZgAAAJYgzAAAACxBmAEAAFiCMAMAALAEYQYAAGAJwgwAAMAShBkAAIAlCDMAAABLEGYAAACWIMwAAAAsQZgBAABYgjADAACwBGEGAABgCcIMAADAEoQZAACAJaIOs927d+vuu+9Wfn6+UlJS9Morr0Ts/973vqeUlJSIbfbs2RFjTp8+rXnz5sntdisrK0sLFizQmTNnruqDAAAAJLqow6yrq0tTpkzR2rVrLzhm9uzZam1tdbZf//rXEfvnzZunw4cPq76+XnV1ddq9e7cWLVoU/ewBAACuIenR/sKcOXM0Z86ci45xuVzyer3n3ff+++9r+/bt2r9/v6ZNmyZJ+vnPf6677rpL//qv/6r8/PxopwQAAHBNGJBrzHbt2qWcnBxNmDBBixcv1qeffursa2xsVFZWlhNlklRSUqLU1FTt27fvvK8XCoUUDAYjNgAAgGtNv4fZ7Nmz9Z//+Z/asWOH/uVf/kUNDQ2aM2eO+vr6JEl+v185OTkRv5Oenq7s7Gz5/f7zvmZtba08Ho+zFRQU9Pe0AQAA4i7qU5mXcv/99zs/T548WUVFRbrxxhu1a9cuzZw584pes6amRtXV1c7jYDBInAEAgGvOgN8u44YbbtDIkSN17NgxSZLX61V7e3vEmN7eXp0+ffqC16W5XC653e6IDQAA4Foz4GH20Ucf6dNPP1VeXp4kyefzqaOjQ01NTc6YnTt3KhwOq7i4eKCnAwAAYK2oT2WeOXPGOfolSSdOnFBzc7Oys7OVnZ2tJ554QuXl5fJ6vTp+/Lh+9KMf6aabblJpaakk6eabb9bs2bO1cOFCrV+/Xj09PaqqqtL999/PNzIBAEBSSzHGmGh+YdeuXfr617/+hecrKiq0bt06zZ07VwcOHFBHR4fy8/M1a9Ys/eQnP1Fubq4z9vTp06qqqtLWrVuVmpqq8vJyrVmzRsOGDbusOQSDQXk8HgUCAU5rAgAAq0XTLVGHmQ0IMwAAkCii6Rb+ViYAAIAlCDMAAABLEGYAAACWIMwAAAAsQZgBAABYgjADAACwBGEGAABgCcIMAADAEoQZAACAJQgzAAAASxBmAAAAliDMAAAALEGYAQAAWCI93hMAgFjb/4tFlzXutn/45QDPBAAiccQMAC4g3NcT7ykASDKEGQBcQLiXMAMQW4QZAFyA6euN9xQAJBnCDAAugFOZAGKNMAOACwj3dsd7CgCSDGEGABfQ1/3neE8BQJIhzADgAjiVCSDWCDMAuABDmAGIMcIMAC6A22UAiDXCDAAugFOZAGKNMAOAC+CIGYBYI8wA4AK4xgxArBFmAHABYe78DyDGCDMAuACuMQMQa4QZAFzAx29vifcUACQZwgwAAMAShBkAAIAlCDMAAABLEGYAAACWIMwAAAAsQZgBAABYgjADAACwRFRhVltbq9tuu03Dhw9XTk6O5s6dq6NHj0aMOXv2rCorKzVixAgNGzZM5eXlamtrixjT0tKisrIyZWZmKicnR8uWLVNvL3fYBgAAyS2qMGtoaFBlZaX27t2r+vp69fT0aNasWerq6nLGLF26VFu3btXmzZvV0NCgU6dO6d5773X29/X1qaysTN3d3dqzZ49eeOEFbdiwQStWrOi/TwUAAJCAUowx5kp/+ZNPPlFOTo4aGhp05513KhAIaNSoUdq4caP+7u/+TpL0wQcf6Oabb1ZjY6OmT5+ubdu26Vvf+pZOnTql3NxcSdL69ev16KOP6pNPPlFGRsYl3zcYDMrj8SgQCMjtdl/p9AEkqf2/WHTZY2/7h18O4EwAJINouuWqrjELBAKSpOzsbElSU1OTenp6VFJS4oyZOHGixowZo8bGRklSY2OjJk+e7ESZJJWWlioYDOrw4cPnfZ9QKKRgMBixAQAAXGuuOMzC4bCWLFmiO+64Q5MmTZIk+f1+ZWRkKCsrK2Jsbm6u/H6/M+avo+zc/nP7zqe2tlYej8fZCgoKrnTaAAAA1rriMKusrNR7772nTZs29ed8zqumpkaBQMDZTp48OeDvCQAAEGvpV/JLVVVVqqur0+7duzV69Gjnea/Xq+7ubnV0dEQcNWtra5PX63XGvP322xGvd+5bm+fGfJ7L5ZLL5bqSqQIAACSMqI6YGWNUVVWlLVu2aOfOnRo3blzE/qlTp2rQoEHasWOH89zRo0fV0tIin88nSfL5fDp06JDa29udMfX19XK73SosLLyazwIA/S7cx618AMROVEfMKisrtXHjRr366qsaPny4c02Yx+PRkCFD5PF4tGDBAlVXVys7O1tut1sPP/ywfD6fpk+fLkmaNWuWCgsL9eCDD2r16tXy+/1avny5KisrOSoGwDqmr1dKu6KTCwAQtaj+b7Nu3TpJ0owZMyKef/755/W9731PkvT0008rNTVV5eXlCoVCKi0t1XPPPeeMTUtLU11dnRYvXiyfz6ehQ4eqoqJCTz755NV9EgAYAOG+HqVpcLynASBJXNV9zOKF+5gBuBrR3Mds8v0/0WBP7qUHAsAFxOw+ZgBwrQv39sR7CgCSCGEGABcR7iPMAMQOYQYAF2EIMwAxRJgBwEVwKhNALBFmAHAR3McMQCwRZgBwEeHe7nhPAUASIcwA4CK4xgxALBFmAHARnMoEEEuEGQBcBEfMAMQSYQYAF8F9zADEEmEGIOlcP+1/XfbYj/b9dgBnAgCRCDMASSclbVC8pwAA50WYAUg66a7MeE8BAM6LMAOQdDhiBsBWhBmApJOaTpgBsBNhBiDppHLEDIClCDMASYdTmQBsRZgBSDqpaenxngIAnBdhBiDpcI0ZAFsRZgCSDqcyAdiKMAOQdLj4H4CtCDMASYdTmQBsRZgBSDocMQNgK8IMQNLhGjMAtiLMACQdjpgBsBVhBiDppKRG97++vp7QAM0EACIRZgBwCaavJ95TAJAkCDMAuIQwYQYgRggzALiEcC9hBiA2CDMAuASOmAGIFcIMAC6Ba8wAxAphBgCXwKlMALFCmAHAJYT7euM9BQBJgjADgEvgVCaAWCHMAOASwr3d8Z4CgCQRVZjV1tbqtttu0/Dhw5WTk6O5c+fq6NGjEWNmzJihlJSUiO2hhx6KGNPS0qKysjJlZmYqJydHy5YtU28vpwoA2IlTmQBiJT2awQ0NDaqsrNRtt92m3t5e/dM//ZNmzZqlI0eOaOjQoc64hQsX6sknn3QeZ2ZmOj/39fWprKxMXq9Xe/bsUWtrq+bPn69Bgwbpqaee6oePBAD9i1OZAGIlqjDbvn17xOMNGzYoJydHTU1NuvPOO53nMzMz5fV6z/sav//973XkyBG98cYbys3N1a233qqf/OQnevTRR/X4448rIyPjCj4GAAwc7mMGIFau6hqzQCAgScrOzo54/sUXX9TIkSM1adIk1dTU6LPPPnP2NTY2avLkycrNzXWeKy0tVTAY1OHDh8/7PqFQSMFgMGIDgFjpDX126UEA0A+uOMzC4bCWLFmiO+64Q5MmTXKe/853vqP//u//1ptvvqmamhr913/9l7773e86+/1+f0SUSXIe+/3+875XbW2tPB6PsxUUFFzptAFAkjS6+N7LHnvqnf8zgDMBgP8vqlOZf62yslLvvfee3nrrrYjnFy1a5Pw8efJk5eXlaebMmTp+/LhuvPHGK3qvmpoaVVdXO4+DwSBxBuCqpKYNivcUAOALruiIWVVVlerq6vTmm29q9OjRFx1bXFwsSTp27Jgkyev1qq2tLWLMuccXui7N5XLJ7XZHbABwNVIIMwAWiirMjDGqqqrSli1btHPnTo0bN+6Sv9Pc3CxJysvLkyT5fD4dOnRI7e3tzpj6+nq53W4VFhZGMx0AuGKpaVd8wgAABkxU/2eqrKzUxo0b9eqrr2r48OHONWEej0dDhgzR8ePHtXHjRt11110aMWKEDh48qKVLl+rOO+9UUVGRJGnWrFkqLCzUgw8+qNWrV8vv92v58uWqrKyUy+Xq/08IAOfBETMANorqiNm6desUCAQ0Y8YM5eXlOdtLL70kScrIyNAbb7yhWbNmaeLEiXrkkUdUXl6urVu3Oq+Rlpamuro6paWlyefz6bvf/a7mz58fcd8zABhoqencmgeAfaI6YmaMuej+goICNTQ0XPJ1xo4dq9deey2atwaAfsWpTAA24m9lAkhKqemcygRgH8IMQFLiGjMANiLMACQl7mMGwEaEGYCkxKlMADYizAAkJU5lArARYQYgKXEqE4CNCDMASSktY0i8pwAAX0CYAUhK0d7H7FL3cQSA/kCYAcBlMH098Z4CgCRAmAHAZQgTZgBigDADgMsQ7iXMAAw8wgwALoPp6433FAAkAcIMAC5DuK873lMAkAQIMwC4DJzKBBALhBkAXIYwpzIBxABhBgCXgdtlAIgFwgwALgO3ywAQC4QZAFwGjpgBiAXCDAAuAxf/A4gFwgwALkNv6LN4TwFAEiDMAOAycCoTQCwQZgBwGbhdBoBYIMwAJK3rb//2ZY/9eP8rAzcRAPh/CDMASSs1bVC8pwAAEQgzAAkpJSXlqrfKh/93zN8zJSVlgFYEwLWAMAOQtLp7+uI9BQCIQJgBSFqEGQDbpMd7AgAQL6GeyG9avnfmq2rvHqtQeKhcqV3KyfijJg17K06zA5CMCDMASSv0V0fMtv1pUeS+8FCdPFuok2cLNWfkL2M9NQBJilOZAJJWd+9fwuzzUfZ5l9oPAP2FMAOQtLp7+i47uogzALFAmAFIWp+/xgwA4o0wA5C0Oj/rjvcUACACYQYgaXG7DAC2IcwAJK1QT+9lf+OSb2YCiAXCDEDSOvetzEtFF1EGIFaiCrN169apqKhIbrdbbrdbPp9P27Ztc/afPXtWlZWVGjFihIYNG6by8nK1tbVFvEZLS4vKysqUmZmpnJwcLVu2TL29XIALIPZ6esPOz3NG/lIFg4/IldolSXKldqlg8BGiDEBMRXWD2dGjR2vVqlUaP368jDF64YUXdM899+jAgQO65ZZbtHTpUv3ud7/T5s2b5fF4VFVVpXvvvVd/+MMfJEl9fX0qKyuT1+vVnj171Nraqvnz52vQoEF66qmnBuQDAsDF3P7Qv/3Vo3+74DgAiAlzla677jrzq1/9ynR0dJhBgwaZzZs3O/vef/99I8k0NjYaY4x57bXXTGpqqvH7/c6YdevWGbfbbUKh0GW/ZyAQMJLY2NjY2NjY2BJmCwQCl2ycK/6TTH19fdq8ebO6urrk8/nU1NSknp4elZSUOGMmTpyoMWPGqLGxUdOnT1djY6MmT56s3NxcZ0xpaakWL16sw4cP6ytf+cp53ysUCikUCjmPg8GgJCkQCMjtdl/pRwCQwFJSUuI9hStmjIn3FADEUDAYlMfjuayxUV/8f+jQIQ0bNkwul0sPPfSQtmzZosLCQvn9fmVkZCgrKytifG5urvx+vyTJ7/dHRNm5/ef2XUhtba08Ho+zFRQURDttAAAA60UdZhMmTFBzc7P27dunxYsXq6KiQkeOHBmIuTlqamoUCASc7eTJkwP6fgAAAPEQ9anMjIwM3XTTTZKkqVOnav/+/Xr22Wd13333qbu7Wx0dHRFHzdra2uT1eiVJXq9Xb7/9dsTrnfvW5rkx5+NyueRyuaKdKgAAQEK56vuYhcNhhUIhTZ06VYMGDdKOHTucfUePHlVLS4t8Pp8kyefz6dChQ2pvb3fG1NfXy+12q7Cw8GqnAgAAkNCiOmJWU1OjOXPmaMyYMers7NTGjRu1a9cuvf766/J4PFqwYIGqq6uVnZ0tt9uthx9+WD6fT9OnT5ckzZo1S4WFhXrwwQe1evVq+f1+LV++XJWVlRwRAwAASS+qMGtvb9f8+fPV2toqj8ejoqIivf766/rmN78pSXr66aeVmpqq8vJyhUIhlZaW6rnnnnN+Py0tTXV1dVq8eLF8Pp+GDh2qiooKPfnkk/37qQAAABJQiknA722f+9opt8sAkhe3ywCQKKLpFv5WJgAAgCUIMwAAAEsQZgAAAJYgzAAAACxBmAEAAFiCMAMAALBE1H+SCQBswC0nAFyLOGIGAABgCcIMAADAEoQZAACAJQgzAAAASxBmAAAAliDMAAAALEGYAQAAWIIwAwAAsARhBgAAYAnCDAAAwBKEGQAAgCUIMwAAAEsQZgAAAJYgzAAAACxBmAEAAFiCMAMAALAEYQYAAGAJwgwAAMAShBkAAIAlCDMAAABLEGYAAACWIMwAAAAsQZgBAABYgjADAACwBGEGAABgCcIMAADAEoQZAACAJQgzAAAAS0QVZuvWrVNRUZHcbrfcbrd8Pp+2bdvm7J8xY4ZSUlIitoceeijiNVpaWlRWVqbMzEzl5ORo2bJl6u3t7Z9PAwAAkMDSoxk8evRorVq1SuPHj5cxRi+88ILuueceHThwQLfccoskaeHChXryySed38nMzHR+7uvrU1lZmbxer/bs2aPW1lbNnz9fgwYN0lNPPdVPHwkAACAxpRhjzNW8QHZ2tn76059qwYIFmjFjhm699VY988wz5x27bds2fetb39KpU6eUm5srSVq/fr0effRRffLJJ8rIyLis9wwGg/J4PAoEAnK73VczfQAAgAEVTbdc8TVmfX192rRpk7q6uuTz+ZznX3zxRY0cOVKTJk1STU2NPvvsM2dfY2OjJk+e7ESZJJWWlioYDOrw4cMXfK9QKKRgMBixAQAAXGuiOpUpSYcOHZLP59PZs2c1bNgwbdmyRYWFhZKk73znOxo7dqzy8/N18OBBPfroozp69Kh++9vfSpL8fn9ElElyHvv9/gu+Z21trZ544olopwoAAJBQog6zCRMmqLm5WYFAQC+//LIqKirU0NCgwsJCLVq0yBk3efJk5eXlaebMmTp+/LhuvPHGK55kTU2NqqurncfBYFAFBQVX/HoAAAA2ivpUZkZGhm666SZNnTpVtbW1mjJlip599tnzji0uLpYkHTt2TJLk9XrV1tYWMebcY6/Xe8H3dLlczjdBz20AAADXmqu+j1k4HFYoFDrvvubmZklSXl6eJMnn8+nQoUNqb293xtTX18vtdjunQwEAAJJVVKcya2pqNGfOHI0ZM0adnZ3auHGjdu3apddff13Hjx/Xxo0bddddd2nEiBE6ePCgli5dqjvvvFNFRUWSpFmzZqmwsFAPPvigVq9eLb/fr+XLl6uyslIul2tAPiAAAECiiCrM2tvbNX/+fLW2tsrj8aioqEivv/66vvnNb+rkyZN644039Mwzz6irq0sFBQUqLy/X8uXLnd9PS0tTXV2dFi9eLJ/Pp6FDh6qioiLivmcAAADJ6qrvYxYP3McMAAAkipjcxwwAAAD9izADAACwBGEGAABgCcIMAADAEoQZAACAJQgzAAAASxBmAAAAliDMAAAALEGYAQAAWIIwAwAAsARhBgAAYAnCDAAAwBKEGQAAgCUIMwAAAEsQZgAAAJYgzAAAACxBmAEAAFiCMAMAALAEYQYAAGAJwgwAAMAShBkAAIAlCDMAAABLEGYAAACWIMwAAAAsQZgBAABYgjADAACwBGEGAABgCcIMAADAEoQZAACAJQgzAAAASxBmAAAAliDMAAAALEGYAQAAWIIwAwAAsARhBgAAYAnCDAAAwBKEGQAAgCUIMwAAAEukx3sCV8IYI0kKBoNxngkAAMDFneuVc/1yMQkZZp2dnZKkgoKCOM8EAADg8nR2dsrj8Vx0TIq5nHyzTDgc1tGjR1VYWKiTJ0/K7XbHe0pJIRgMqqCggDWPIdY89ljz2GPNY481jy1jjDo7O5Wfn6/U1ItfRZaQR8xSU1N1/fXXS5Lcbjf/qGKMNY891jz2WPPYY81jjzWPnUsdKTuHi/8BAAAsQZgBAABYImHDzOVyaeXKlXK5XPGeStJgzWOPNY891jz2WPPYY83tlZAX/wMAAFyLEvaIGQAAwLWGMAMAALAEYQYAAGAJwgwAAMAShBkAAIAlCDMAAABLEGYAAACWIMwAAAAs8X8BLDgjPi4ix9UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_obs, _ = env.reset()\n",
    "test_obs\n",
    "\n",
    "frame = env.render()\n",
    "frame = np.rot90(frame, 2)\n",
    "frame = np.flipud(frame)\n",
    "plt.matshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf47e5204d9af2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:09:14.547142100Z",
     "start_time": "2023-10-18T20:09:14.531601400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce87a3100a40351b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:09:14.550150800Z",
     "start_time": "2023-10-18T20:09:14.542117700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e378e253214ee8a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Set up initial parameters for Q-learning:\n",
    "\n",
    "**$\\alpha$ = 0.075** is the learning rate;\n",
    "**$\\epsilon$ = 1.0** is the initial value that will be used in Exploration-Exploitation trade-off for $\\epsilon$-greedy algorithm;\n",
    "**$\\gamma$ = 0.95** is the discount factor, the higher the $\\gamma$, the more the weightage of future states on the returns\n",
    "**$\\epsilon$-decay** = 0.995\n",
    "\n",
    "**Q-table** : Initially a 25x25x25x25x2 tensor with zeroes, because we will be testing 25 different values for each of the 4 states against 2 possible actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c8eb8d26d25ed7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:09:14.763007200Z",
     "start_time": "2023-10-18T20:09:14.702400500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set initial parameters\n",
    "params = {'alpha':0.075, 'gamma':0.95, 'epsilon':1.0}\n",
    "\n",
    "# Initialize Q-table\n",
    "n_actions = env.action_space.n\n",
    "state_bins = [np.linspace(-x, x, num=24) for x in env.observation_space.high]\n",
    "Q_table = np.zeros([len(bin) + 1 for bin in state_bins] + [n_actions])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206386f05e3775ae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Define a Policy**\n",
    "I am going to explore three different policies:\n",
    "   * User Controlled (``rl=no-policy``) : User plays the game with keyboard inputs\n",
    "    * Harcoded policy (``rl='basic'``) : A simple rule based policy that moves the cart to right if the pole tilts right and moves the cart left if the pole tilts left, in order to balance the pole.\n",
    "   * Q-learning based policy (``rl='q-learning'``) : Applies **Q-learning** to learn by interacting with the environment on it's own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30138ad94802a5ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:19:00.976842600Z",
     "start_time": "2023-10-18T20:19:00.956634300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def policy(obs, rl='no-policy'):\n",
    "    action = None\n",
    "    \n",
    "    if rl == 'no-policy':\n",
    "        return action\n",
    "\n",
    "    if rl=='basic':\n",
    "        angle = obs[2]\n",
    "        action = 1 if angle>0 else 0\n",
    "        return action\n",
    "    \n",
    "    if rl=='q-learning':            \n",
    "        # Choose action as per epsilon-greedy method\n",
    "        if np.random.rand()<params['epsilon']:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(Q_table[obs])\n",
    "        \n",
    "        # epsilon-decay\n",
    "        if params['epsilon']>0.1:\n",
    "            params['epsilon']*=0.995\n",
    "        return action   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ae9d675dce314",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Update the Q-table**\n",
    "This step is the essence of Q-learning, the Q-table initialized above gets updated based next state, action and reward as per the following expression:\n",
    "\n",
    "$$\n",
    "Q(s, a) \\leftarrow (1 - \\alpha) \\cdot Q(s, a) + \\alpha \\cdot (r + \\gamma \\cdot \\max_{a'} Q(s', a'))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7bda4a98064244b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:09:15.367689900Z",
     "start_time": "2023-10-18T20:09:15.328926300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update Q-table\n",
    "def update_Q(obs, action, reward):\n",
    "    best_next_action = np.argmax(Q_table[obs])\n",
    "    Q_table[obs][action] = (1 - params['alpha']) * Q_table[obs][action] + params['alpha'] * (reward + params['gamma'] * Q_table[obs][best_next_action])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67afa2714a5434",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following function is simply to discretize the state space returned by CartPole so that it's compatible with the Q-table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15dee5f717e044ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:09:16.443556200Z",
     "start_time": "2023-10-18T20:09:16.414700700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Will be used to discretize the state space as CartPole returns a continuous space \n",
    "def discretize(state):\n",
    "    state_indices = []\n",
    "    for i in range(len(state)):\n",
    "        lower_bound = state_bins[i][0] if isinstance(state_bins[i][0], (int, float)) else state_bins[i][0][0]\n",
    "        upper_bound = state_bins[i][-1] if isinstance(state_bins[i][-1], (int, float)) else state_bins[i][-1][-1]\n",
    "\n",
    "        if state[i] <= lower_bound:\n",
    "            state_index = 0\n",
    "        elif state[i] >= upper_bound:\n",
    "            state_index = len(state_bins[i]) - 1\n",
    "        else:\n",
    "            state_index = np.digitize(state[i], state_bins[i]) - 1\n",
    "        state_indices.append(state_index)\n",
    "\n",
    "\n",
    "    return tuple(state_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca586d17805c95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Draw the Game Screen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3afdfdbca969f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:09:16.757590Z",
     "start_time": "2023-10-18T20:09:16.747561Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run animations\n",
    "def animate(env, win, clock, episode_rewards, env_rewards, policy_type):\n",
    "    clock.tick(15)\n",
    "    run = True\n",
    "    frame = env.render()\n",
    "    frame = np.rot90(frame)\n",
    "    frame = np.flipud(frame)\n",
    "    \n",
    "    font = pg.font.Font(None, 36)\n",
    "    text_surface_current = font.render('Current Score: '+ str(episode_rewards), True, (100,0,0))\n",
    "    text_surface_high = font.render('Highest Score: '+str(max(env_rewards[policy_type])), True, (0,100,100))\n",
    "    surface = pg.surfarray.make_surface(frame)\n",
    "    \n",
    "    win.blit(surface, (0, 0))\n",
    "    win.blit(text_surface_current, (0, 0))\n",
    "    win.blit(text_surface_high, (0, 40))\n",
    "    pg.display.update()\n",
    "\n",
    "    for event in pg.event.get():\n",
    "        if event.type == pg.QUIT:\n",
    "            run = False\n",
    "            pg.quit()\n",
    "    return run\n",
    "            \n",
    "# User controlled settings if no policy     \n",
    "def run_by_user(animation):\n",
    "    action = None\n",
    "    if animation:\n",
    "        user_input = pg.key.get_pressed()\n",
    "        if user_input[pg.K_RIGHT]:\n",
    "            action = 1\n",
    "        elif user_input[pg.K_LEFT]:\n",
    "            action = 0\n",
    "        return action\n",
    "    else:\n",
    "        raise ValueError('Animation must be True in user-controlled policy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046d0b5bdc5f63c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Simulate**\n",
    "Next, I shall create some functions to simulate the CartPole environment based on different policies. The first two policies are self-explanatory, while the Q-learning policy simply starts by taking an action based on the $\\epsilon$-greedy algorigthm, and then updates the Q-values until it reaches satisfactory score or is halted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bb918814a2cdba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:18:47.964135Z",
     "start_time": "2023-10-18T20:18:47.940215200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_rewards = {'no-policy':[0], 'basic':[0], 'q-learning':[0]}\n",
    "\n",
    "# Main function to run the simulation\n",
    "def simulate_episode(env, policy_type='no-policy', animation=True):\n",
    "    obs, info = env.reset()                                                 #  0 Get initial state of the env\n",
    "    obs = discretize(obs)\n",
    "    clock = pg.time.Clock()\n",
    "    \n",
    "    # Initialize Pygame if animation is True\n",
    "    if animation:\n",
    "        clock.tick(15)\n",
    "        win = pg.display.set_mode((600, 400))\n",
    "        pg.init()\n",
    "        run = True\n",
    "    else:\n",
    "        run = 500\n",
    "\n",
    "\n",
    "    episode_rewards = 0                                                         #1  Initialize rewards\n",
    "    while run:        \n",
    "        action=policy(obs, policy_type)                                         #2  Choose an action based on policy\n",
    "        \n",
    "        if action is None:                                                      #  If user-controlled\n",
    "            action = run_by_user(animation)\n",
    "                \n",
    "        if action is not None:\n",
    "            obs, reward, done, truncated, info = env.step(action)               #3  Take the decided action to reach next state\n",
    "            \n",
    "            episode_rewards += reward                                           #5  Update rewards\n",
    "            if policy_type=='q-learning':\n",
    "                obs = discretize(obs)\n",
    "                update_Q(obs, action, reward)                                   #6  Update Q-values\n",
    "                \n",
    "            if done:                                                \n",
    "                obs, info = env.reset()\n",
    "                break\n",
    "        \n",
    "        if animation:\n",
    "            run = animate(env, win, clock, episode_rewards, env_rewards, policy_type)\n",
    "        else:\n",
    "            run-=1\n",
    "    \n",
    "    env_rewards[policy_type].append(episode_rewards)\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e0fb55e5bdf30d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:41:10.276418Z",
     "start_time": "2023-10-18T20:41:00.270943500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulate_episode(env, policy_type='no-policy', animation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81dd3a067b1787",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**1. User Controlled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d17d8eb8a01393e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:15:23.065656200Z",
     "start_time": "2023-10-18T20:15:23.060649100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reset the scores (Rewards)\n",
    "env_rewards = {'no-policy':[0], 'basic':[0], 'q-learning':[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c108dfe74b352f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:42:50.463646200Z",
     "start_time": "2023-10-18T20:42:47.403515Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_episode(env, policy_type='no-policy', animation=True)\n",
    "max(env_rewards['no-policy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5809e3bb6b6f783",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**2. Basic Hardcoded Policy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec4e10507eee5c61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:43:35.322248900Z",
     "start_time": "2023-10-18T20:43:27.114343100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thory/miniconda3/envs/small-projects-ml/lib/python3.12/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for episode in range(2):    \n",
    "    simulate_episode(env, policy_type='basic', animation=True)\n",
    "max(env_rewards['basic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a7f0fc87e6f81",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**3. Q-Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9378dce1f5896160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-18T20:43:57.149139100Z",
     "start_time": "2023-10-18T20:43:42.942314300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for episode in range(10):\n",
    "    simulate_episode(env, policy_type='q-learning', animation=True)\n",
    "max(env_rewards['q-learning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a40a81e",
   "metadata": {},
   "source": [
    "**4. Policy Gradients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    layers=[\n",
    "        keras.layers.Input((4,)),\n",
    "        keras.layers.Dense(100),\n",
    "        keras.layers.Dense(1, activation=keras.activations.sigmoid)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61dfa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, obs, model, loss_fn):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(obs[np.newaxis])\n",
    "        action = (tf.random.uniform([1,1])>y_pred)\n",
    "        y = tf.math.subtract(tf.constant([[1.]]),tf.cast(action, tf.float32))\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    obs, reward, done, _, _ = env.step(int(action[0,0].numpy()))\n",
    "    return obs, reward, done, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9a7b6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04803272,  0.00401143, -0.0173563 , -0.01477358], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def play_episodes(env, n_episodes, max_steps, model, loss_fn):\n",
    "    all_rewards=[]\n",
    "    all_gradients=[]\n",
    "    for episode in range(n_episodes):\n",
    "        current_rewards=[]\n",
    "        current_grads=[]\n",
    "        obs = env.reset()[0]\n",
    "        for step in range(max_steps):\n",
    "            obs, reward, done, grads = play_one_step(env, obs, model, loss_fn)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc4e2403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.03903922,  0.22061522, -0.00955389, -0.31606457], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " [<tf.Tensor: shape=(4, 100), dtype=float32, numpy=\n",
       "  array([[-2.31532473e-03, -4.19241423e-03,  4.68040677e-03,\n",
       "          -5.36726206e-04,  2.89327186e-03, -4.30647098e-03,\n",
       "           4.58877953e-03,  4.00914205e-03, -1.16808550e-03,\n",
       "          -2.40440271e-03, -2.05106311e-03, -3.48032825e-03,\n",
       "          -1.12766947e-03, -3.45815206e-03, -1.82584941e-03,\n",
       "          -4.22019605e-03,  1.78392616e-03, -3.18843685e-03,\n",
       "          -1.95198169e-03,  3.04061896e-03, -3.41821020e-03,\n",
       "           2.05092551e-03, -3.18053341e-03,  3.61402682e-03,\n",
       "           3.89516004e-03,  1.84792664e-03, -5.61965222e-04,\n",
       "          -2.12889700e-03,  3.51874880e-03, -1.16602995e-03,\n",
       "           3.86378448e-03, -2.50073965e-03, -2.44952133e-03,\n",
       "          -1.23609020e-03,  4.57756268e-03,  2.28853454e-03,\n",
       "          -2.89340527e-03, -2.98915710e-03,  2.21167458e-03,\n",
       "           5.41224785e-04,  3.23855830e-03, -4.45088232e-03,\n",
       "           2.57621519e-03, -9.25813976e-04,  1.42988632e-03,\n",
       "           4.12110530e-05,  3.58205056e-03,  7.10396795e-04,\n",
       "          -2.13681185e-03, -2.70248216e-04,  4.25618142e-03,\n",
       "          -3.01629188e-03, -4.00472432e-03, -4.48946748e-03,\n",
       "          -2.84695602e-03, -3.04724602e-03, -4.60684299e-03,\n",
       "          -2.23288033e-03,  1.91306823e-03,  2.22280947e-03,\n",
       "           6.01734646e-05,  2.80621898e-04,  6.27779576e-04,\n",
       "           1.40795147e-03,  3.58999893e-03, -1.61979769e-04,\n",
       "           2.46720226e-03,  1.95411663e-03,  3.45517974e-03,\n",
       "          -3.93071072e-03,  1.14486604e-04, -2.18787973e-04,\n",
       "           3.16334679e-03, -1.80925374e-04, -3.63563327e-03,\n",
       "          -2.16845982e-03, -5.12719795e-04,  6.33234624e-04,\n",
       "           1.56794806e-04,  8.37286701e-04,  3.09899775e-03,\n",
       "           9.89782624e-04, -4.34886059e-03, -3.79776442e-03,\n",
       "           1.16288813e-03,  3.12684104e-03,  1.80223142e-03,\n",
       "          -7.33001158e-04, -2.24413234e-04,  2.90877325e-03,\n",
       "           4.30204207e-03,  1.17251754e-03, -2.32125144e-03,\n",
       "          -3.03836679e-03, -3.60779086e-05, -3.12550738e-03,\n",
       "           4.59595257e-03, -4.49671643e-03, -2.15301407e-03,\n",
       "          -3.83605948e-03],\n",
       "         [-1.52404362e-03, -2.75962241e-03,  3.08083929e-03,\n",
       "          -3.53295618e-04,  1.90447248e-03, -2.83469912e-03,\n",
       "           3.02052638e-03,  2.63898494e-03, -7.68882746e-04,\n",
       "          -1.58267841e-03, -1.35009538e-03, -2.29089754e-03,\n",
       "          -7.42279168e-04, -2.27630022e-03, -1.20185036e-03,\n",
       "          -2.77790939e-03,  1.17425481e-03, -2.09876243e-03,\n",
       "          -1.28487591e-03,  2.00146250e-03, -2.25000898e-03,\n",
       "           1.35000492e-03, -2.09356006e-03,  2.37890356e-03,\n",
       "           2.56395736e-03,  1.21638260e-03, -3.69909016e-04,\n",
       "          -1.40132906e-03,  2.31618760e-03, -7.67529651e-04,\n",
       "           2.54330458e-03, -1.64609135e-03, -1.61237735e-03,\n",
       "          -8.13646242e-04,  3.01314308e-03,  1.50640914e-03,\n",
       "          -1.90456025e-03, -1.96758821e-03,  1.45581667e-03,\n",
       "           3.56256787e-04,  2.13175453e-03, -2.92975688e-03,\n",
       "           1.69577263e-03, -6.09409472e-04,  9.41210950e-04,\n",
       "           2.71268382e-05,  2.35785544e-03,  4.67612874e-04,\n",
       "          -1.40653900e-03, -1.77888680e-04,  2.80159642e-03,\n",
       "          -1.98544934e-03, -2.63607712e-03, -2.95515521e-03,\n",
       "          -1.87398551e-03, -2.00582482e-03, -3.03241680e-03,\n",
       "          -1.46977522e-03,  1.25926151e-03,  1.46314607e-03,\n",
       "           3.96086907e-05,  1.84717079e-04,  4.13230766e-04,\n",
       "           9.26772482e-04,  2.36308738e-03, -1.06621854e-04,\n",
       "           1.62401574e-03,  1.28628127e-03,  2.27434374e-03,\n",
       "          -2.58735823e-03,  7.53598651e-05, -1.44015386e-04,\n",
       "           2.08224705e-03, -1.19092641e-04, -2.39312579e-03,\n",
       "          -1.42737094e-03, -3.37493606e-04,  4.16821509e-04,\n",
       "           1.03208899e-04,  5.51137084e-04,  2.03988981e-03,\n",
       "           6.51516311e-04, -2.86260177e-03, -2.49984721e-03,\n",
       "           7.65461591e-04,  2.05821753e-03,  1.18630414e-03,\n",
       "          -4.82492032e-04, -1.47718165e-04,  1.91467616e-03,\n",
       "           2.83178384e-03,  7.71800114e-04, -1.52794481e-03,\n",
       "          -1.99998007e-03, -2.37479871e-05, -2.05733976e-03,\n",
       "           3.02524818e-03, -2.95992661e-03, -1.41720392e-03,\n",
       "          -2.52505485e-03],\n",
       "         [ 5.49429154e-04,  9.94864618e-04, -1.11066573e-03,\n",
       "           1.27365711e-04, -6.86576590e-04,  1.02193025e-03,\n",
       "          -1.08892238e-03, -9.51373833e-04,  2.77187995e-04,\n",
       "           5.70567441e-04,  4.86719509e-04,  8.25885742e-04,\n",
       "           2.67597206e-04,  8.20623303e-04,  4.33276087e-04,\n",
       "           1.00145710e-03, -4.23327641e-04,  7.56619615e-04,\n",
       "           4.63207398e-04, -7.21542223e-04,  8.11145059e-04,\n",
       "          -4.86686884e-04,  7.54744106e-04, -8.57612584e-04,\n",
       "          -9.24325781e-04, -4.38515039e-04,  1.33354974e-04,\n",
       "           5.05189644e-04, -8.35002982e-04,  2.76700186e-04,\n",
       "          -9.16880323e-04,  5.93428267e-04,  5.81274100e-04,\n",
       "           2.93325575e-04, -1.08626066e-03, -5.43071772e-04,\n",
       "           6.86608255e-04,  7.09330314e-04, -5.24832809e-04,\n",
       "          -1.28433239e-04, -7.68513477e-04,  1.05619931e-03,\n",
       "          -6.11338706e-04,  2.19696682e-04, -3.39313614e-04,\n",
       "          -9.77942818e-06, -8.50024517e-04, -1.68577943e-04,\n",
       "           5.07067831e-04,  6.41302031e-05, -1.00999651e-03,\n",
       "           7.15769420e-04,  9.50325571e-04,  1.06535561e-03,\n",
       "           6.75585819e-04,  7.23114819e-04,  1.09320891e-03,\n",
       "           5.29864978e-04, -4.53973218e-04, -5.27475146e-04,\n",
       "          -1.42792296e-05, -6.65918851e-05, -1.48972787e-04,\n",
       "          -3.34108423e-04, -8.51910736e-04,  3.84379782e-05,\n",
       "          -5.85469825e-04, -4.63714008e-04, -8.19917943e-04,\n",
       "           9.32761992e-04, -2.71677964e-05,  5.19186251e-05,\n",
       "          -7.50665669e-04,  4.29337888e-05,  8.62739806e-04,\n",
       "           5.14577900e-04,  1.21668978e-04, -1.50267282e-04,\n",
       "          -3.72075810e-05, -1.98689057e-04, -7.35395588e-04,\n",
       "          -2.34876512e-04,  1.03198935e-03,  9.01213672e-04,\n",
       "          -2.75954633e-04, -7.42002798e-04, -4.27671504e-04,\n",
       "           1.73941997e-04,  5.32535050e-05, -6.90255081e-04,\n",
       "          -1.02087925e-03, -2.78239721e-04,  5.50835568e-04,\n",
       "           7.21007760e-04,  8.56132738e-06,  7.41686381e-04,\n",
       "          -1.09062460e-03,  1.06707576e-03,  5.10912621e-04,\n",
       "           9.10301169e-04],\n",
       "         [ 1.23246049e-03,  2.23164586e-03, -2.49140710e-03,\n",
       "           2.85702379e-04, -1.54010497e-03,  2.29235878e-03,\n",
       "          -2.44263327e-03, -2.13408889e-03,  6.21778541e-04,\n",
       "           1.27987727e-03,  1.09179248e-03,  1.85259851e-03,\n",
       "           6.00264815e-04,  1.84079399e-03,  9.71909962e-04,\n",
       "           2.24643410e-03, -9.49594018e-04,  1.69722305e-03,\n",
       "           1.03905087e-03, -1.61853863e-03,  1.81953271e-03,\n",
       "          -1.09171926e-03,  1.69301592e-03, -1.92376703e-03,\n",
       "          -2.07341579e-03, -9.83661856e-04,  2.99137260e-04,\n",
       "           1.13322400e-03, -1.87304989e-03,  6.20684354e-04,\n",
       "          -2.05671438e-03,  1.33115787e-03,  1.30389410e-03,\n",
       "           6.57977827e-04, -2.43666256e-03, -1.21819996e-03,\n",
       "           1.54017599e-03,  1.59114529e-03, -1.17728696e-03,\n",
       "          -2.88097013e-04, -1.72390288e-03,  2.36922991e-03,\n",
       "          -1.37133396e-03,  4.92816034e-04, -7.61136587e-04,\n",
       "          -2.19368776e-05, -1.90674572e-03, -3.78148252e-04,\n",
       "           1.13743707e-03,  1.43854661e-04, -2.26558931e-03,\n",
       "           1.60558929e-03,  2.13173754e-03,  2.38976907e-03,\n",
       "           1.51545077e-03,  1.62206625e-03,  2.45224871e-03,\n",
       "           1.18857482e-03, -1.01833709e-03, -1.18321402e-03,\n",
       "          -3.20306754e-05, -1.49376632e-04, -3.34170618e-04,\n",
       "          -7.49460538e-04, -1.91097683e-03,  8.62227462e-05,\n",
       "          -1.31330581e-03, -1.04018732e-03, -1.83921168e-03,\n",
       "           2.09233956e-03, -6.09418676e-05,  1.16462077e-04,\n",
       "          -1.68386742e-03,  9.63076018e-05,  1.93526817e-03,\n",
       "           1.15428341e-03,  2.72923673e-04, -3.37074394e-04,\n",
       "          -8.34627645e-05, -4.45692451e-04, -1.64961407e-03,\n",
       "          -5.26866876e-04,  2.31492310e-03,  2.02157139e-03,\n",
       "          -6.19011931e-04, -1.66443514e-03, -9.59338038e-04,\n",
       "           3.90180678e-04,  1.19456432e-04, -1.54835649e-03,\n",
       "          -2.29000137e-03, -6.24137756e-04,  1.23561535e-03,\n",
       "           1.61733979e-03,  1.92044754e-05,  1.66372536e-03,\n",
       "          -2.44645146e-03,  2.39362754e-03,  1.14606158e-03,\n",
       "           2.04195618e-03]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "  array([-0.06008844, -0.10880359,  0.12146821, -0.01392938,  0.07508761,\n",
       "         -0.11176364,  0.11909025,  0.10404722, -0.03031473, -0.06240024,\n",
       "         -0.05323019, -0.09032319, -0.02926583, -0.08974766, -0.04738534,\n",
       "         -0.10952459,  0.04629733, -0.08274788, -0.05065878,  0.07891163,\n",
       "         -0.08871107,  0.05322662, -0.08254276,  0.093793  ,  0.10108911,\n",
       "          0.0479583 , -0.0145844 , -0.05525018,  0.09132029, -0.03026138,\n",
       "          0.10027483, -0.06490042, -0.06357118, -0.03207962,  0.11879915,\n",
       "          0.05939317, -0.07509107, -0.07757607,  0.05739846,  0.01404613,\n",
       "          0.08404865, -0.11551148,  0.0668592 , -0.02402718,  0.03710911,\n",
       "          0.00106953,  0.09296313,  0.01843657, -0.05545559, -0.00701361,\n",
       "          0.1104585 , -0.07828029, -0.10393257, -0.11651286, -0.0738856 ,\n",
       "         -0.07908362, -0.11955905, -0.05794881,  0.04964888,  0.05768744,\n",
       "          0.00156165,  0.00728284,  0.01629244,  0.03653985,  0.09316941,\n",
       "         -0.00420378,  0.06403004,  0.05071419,  0.08967052, -0.10201173,\n",
       "          0.00297121, -0.00567809,  0.08209673, -0.00469546, -0.09435374,\n",
       "         -0.05627693, -0.01330636,  0.01643402,  0.00406922,  0.02172967,\n",
       "          0.08042671,  0.02568732, -0.11286376, -0.09856144,  0.03017984,\n",
       "          0.08114931,  0.04677239, -0.01902321, -0.00582408,  0.07548991,\n",
       "          0.1116487 ,  0.03042975, -0.06024226, -0.07885318, -0.00093631,\n",
       "         -0.0811147 ,  0.11927641, -0.11670098, -0.05587608, -0.0995553 ],\n",
       "        dtype=float32)>,\n",
       "  <tf.Tensor: shape=(100, 1), dtype=float32, numpy=\n",
       "  array([[-4.5230971e-03],\n",
       "         [-4.4030617e-03],\n",
       "         [ 1.6029276e-03],\n",
       "         [-1.0318529e-03],\n",
       "         [ 4.0007476e-03],\n",
       "         [ 8.4827552e-05],\n",
       "         [ 3.6816248e-06],\n",
       "         [ 1.8056270e-03],\n",
       "         [-3.1746095e-03],\n",
       "         [-2.9801619e-03],\n",
       "         [ 1.4204014e-04],\n",
       "         [-2.6953784e-03],\n",
       "         [-3.9757488e-04],\n",
       "         [ 5.0278171e-03],\n",
       "         [-1.4702093e-03],\n",
       "         [-1.5982401e-03],\n",
       "         [-4.6912223e-04],\n",
       "         [-2.6658985e-03],\n",
       "         [-2.8461614e-03],\n",
       "         [ 9.5169683e-04],\n",
       "         [ 9.5107954e-04],\n",
       "         [ 3.8886340e-03],\n",
       "         [-4.6294751e-03],\n",
       "         [ 2.4056204e-03],\n",
       "         [ 7.6577938e-03],\n",
       "         [ 9.8794873e-04],\n",
       "         [-1.1811834e-03],\n",
       "         [ 2.0534289e-03],\n",
       "         [-4.7684587e-03],\n",
       "         [ 3.1951102e-04],\n",
       "         [-4.0707118e-03],\n",
       "         [-3.5898057e-03],\n",
       "         [-5.3163158e-04],\n",
       "         [-4.1794544e-03],\n",
       "         [ 2.5953611e-03],\n",
       "         [-1.0007611e-03],\n",
       "         [ 3.1063785e-03],\n",
       "         [ 2.2309134e-03],\n",
       "         [ 4.9449382e-03],\n",
       "         [ 1.4118262e-03],\n",
       "         [ 9.4822724e-04],\n",
       "         [ 5.1859603e-03],\n",
       "         [ 2.9956310e-03],\n",
       "         [-1.7594725e-03],\n",
       "         [-6.1151171e-03],\n",
       "         [-3.7552598e-03],\n",
       "         [ 2.4090940e-03],\n",
       "         [-4.6083424e-03],\n",
       "         [ 8.1769278e-05],\n",
       "         [ 1.7605512e-04],\n",
       "         [-2.6155352e-03],\n",
       "         [-1.5776830e-03],\n",
       "         [-5.2491098e-04],\n",
       "         [-1.3725477e-03],\n",
       "         [ 8.5218687e-04],\n",
       "         [-2.8450252e-04],\n",
       "         [-3.3028990e-03],\n",
       "         [-7.3490422e-03],\n",
       "         [ 3.5748177e-03],\n",
       "         [-9.2444656e-04],\n",
       "         [ 6.2152692e-03],\n",
       "         [ 4.0500890e-03],\n",
       "         [ 3.3566330e-03],\n",
       "         [-1.9943418e-03],\n",
       "         [ 4.3900013e-03],\n",
       "         [ 1.3132581e-03],\n",
       "         [-2.7179534e-03],\n",
       "         [-7.0916337e-04],\n",
       "         [ 4.6169534e-03],\n",
       "         [-7.6718093e-03],\n",
       "         [ 4.7269538e-03],\n",
       "         [-1.8396265e-03],\n",
       "         [ 5.3151138e-03],\n",
       "         [-3.4676815e-04],\n",
       "         [ 1.4796476e-03],\n",
       "         [ 1.8817113e-03],\n",
       "         [ 2.7757941e-03],\n",
       "         [ 4.5842719e-03],\n",
       "         [ 4.7159183e-06],\n",
       "         [-1.5313969e-03],\n",
       "         [ 3.1043952e-03],\n",
       "         [-2.6876747e-03],\n",
       "         [ 6.7871287e-03],\n",
       "         [ 5.2820314e-03],\n",
       "         [ 3.0395607e-03],\n",
       "         [ 4.2191683e-03],\n",
       "         [ 2.9955024e-03],\n",
       "         [ 8.4485975e-04],\n",
       "         [ 5.5200765e-03],\n",
       "         [-7.5238766e-03],\n",
       "         [ 5.7380198e-04],\n",
       "         [ 3.8506454e-03],\n",
       "         [ 1.0707919e-03],\n",
       "         [ 3.2728228e-03],\n",
       "         [-5.3076809e-03],\n",
       "         [ 1.1556585e-03],\n",
       "         [ 1.5081343e-03],\n",
       "         [ 1.7285800e-03],\n",
       "         [ 7.8148459e-04],\n",
       "         [-1.5119871e-03]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5041789], dtype=float32)>])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def play_episodes(env, n_episodes, max_steps, model, loss_fn):\n",
    "    all_rewards = []\n",
    "    all_gradients = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        current_rewards = []\n",
    "        current_gradients = []\n",
    "        \n",
    "        obs = env.reset()[0]\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            obs, reward, done, grads = play_one_step(env, obs, model, loss_fn)\n",
    "            \n",
    "            current_rewards.append(reward)\n",
    "            current_gradients.append(grads)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        all_rewards.append(current_rewards)\n",
    "        all_gradients.append(current_gradients)\n",
    "    \n",
    "    return all_rewards, all_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b6277c317c11a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Kartik Kumar** <br>\n",
    "For more such projects, visit [My GitHub Page](https://github.com/ryuukkk?tab=repositories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
