{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.Tensor` and `tf.Variable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T12:01:36.121977Z",
     "start_time": "2024-11-02T12:01:36.120179Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T12:01:44.603171Z",
     "start_time": "2024-11-02T12:01:44.599745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\n",
       "array([[ 1,  2,  3,  4],\n",
       "       [ 2,  4,  6,  8],\n",
       "       [ 3,  6,  9, 12],\n",
       "       [ 4,  8, 12, 16]], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3,4]], dtype=tf.int32)\n",
    "tf.transpose(a) @ a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T12:01:46.391933Z",
     "start_time": "2024-11-02T12:01:46.388009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12), dtype=int32, numpy=array([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([a,a,a], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T12:02:01.257861Z",
     "start_time": "2024-11-02T12:02:01.249376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(1, 4) dtype=int32, numpy=array([[2, 4, 6, 8]], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(a)\n",
    "v.assign_add(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T12:02:04.252195Z",
     "start_time": "2024-11-02T12:02:04.249931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shape returns a `TensorShape` object that shows the size along each axis\n",
    "x = tf.constant([[1], [2], [3]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T12:02:07.769856Z",
     "start_time": "2024-11-02T12:02:07.767924Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def my_func(x):\n",
    "  print('Tracing.\\n')\n",
    "  return tf.reduce_sum(x)\n",
    "\n",
    "# everytime shape or dtype of x changes, a new graph is generated\n",
    "# non-tf ops are only run once, during the first call of the function, and ignored in all subsequent calls,\n",
    "# because the the first time the function is called, it's compiled in a static graph which is run on each subsequent call of that function. \n",
    "# non-tf ops are not a part of this graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T12:02:33.967743Z",
     "start_time": "2024-11-02T12:02:33.965156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func(tf.constant([1,2,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(my_func, 'myfunc') \n",
    "# only works with objects of subclasses of tf.Module, like keras.Model or keras.layers.Layer\n",
    "# @tf. functions should only contain tf ops, and avoid python ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]\n",
    "\n",
    "tf.ragged.constant(ragged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# If you have three string tensors of different lengths, this is OK.\n",
    "tensor_of_strings = tf.constant([\"Gray wolf\",\n",
    "                                 \"Quick brown fox\",\n",
    "                                 \"Lazy dog\"])\n",
    "# Note that the shape is (3,). The string length is not included.\n",
    "print(tensor_of_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, None])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.split(tensor_of_strings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'1 10 100'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = tf.constant(\"1 10 100\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([  1.,  10., 100.], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.to_number(tf.strings.split(text, \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)\n",
      "Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "byte_strings = tf.strings.bytes_split(tf.constant(\"Duck\"))\n",
    "byte_ints = tf.io.decode_raw(tf.constant(\"Duck\"), tf.uint8)\n",
    "print(\"Byte strings:\", byte_strings)\n",
    "print(\"Bytes:\", byte_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
    "x = [[1., 2., 3.]]\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  y = x @ w + b\n",
    "  loss = tf.reduce_mean(y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.28481627,  1.3564167 ],\n",
       "        [-0.56963253,  2.7128334 ],\n",
       "        [-0.8544488 ,  4.06925   ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.28481627,  1.3564167 ], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(loss, [w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[0.       , 0.8670832],\n",
       "        [0.       , 1.7341664],\n",
       "        [0.       , 2.6012497]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.       , 0.8670832], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = tf.keras.layers.Dense(2, activation='relu')\n",
    "x = tf.constant([[1., 2., 3.]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  # Forward pass\n",
    "  y = layer(x)\n",
    "  loss = tf.reduce_mean(y**2)\n",
    "\n",
    "# Calculate gradients with respect to every trainable variable\n",
    "grad = tape.gradient(loss, layer.trainable_variables)\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.37591663>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# A trainable variable\n",
    "x0 = tf.Variable(3.0, name='x0')\n",
    "# Not trainable\n",
    "x1 = tf.Variable(3.0, name='x1', trainable=False)\n",
    "# Not a Variable: A variable + tensor returns a tensor.\n",
    "x2 = tf.Variable(2.0, name='x2') + 1.0\n",
    "# Not a variable\n",
    "x3 = tf.constant(3.0, name='x3')\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = (x0**2) + (x1**2) + (x2**2)\n",
    "\n",
    "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
    "\n",
    "for g in grad:\n",
    "  print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x0:0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[var.name for var in tape.watched_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable + Tensor = Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)\n",
    "  y = x**2\n",
    "\n",
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx.numpy())\n",
    "#Conversely, to disable the default behavior of \n",
    "# watching all tf.Variables, set watch_accessed_\n",
    "# variables=False when creating the gradient tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4. 108.]\n",
      "[2. 6.]\n"
     ]
    }
   ],
   "source": [
    "# Persistent Tape\n",
    "x = tf.constant([1, 3.0])\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  tape.watch(x)\n",
    "  y = x * x\n",
    "  z = y * y\n",
    "\n",
    "print(tape.gradient(z, x).numpy())  # [4.0, 108.0] (4 * x**3 at x = [1.0, 3.0])\n",
    "print(tape.gradient(y, x).numpy())  # [2.0, 6.0] (2 * x at x = [1.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tape context ONLY where required, it uses memory to hold intermediate results\n",
    "# multiple/multivariate targets -> returns sum of gradients; multiple sources -> returns multiple outputs\n",
    "# if dont need sum and need separate for multivar -> use Jacobians instead of Gradients\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(201,), dtype=float32, numpy=\n",
       "array([4.53958055e-05, 5.01696704e-05, 5.54454418e-05, 6.12759977e-05,\n",
       "       6.77195349e-05, 7.48406237e-05, 8.27104013e-05, 9.14074917e-05,\n",
       "       1.01019010e-04, 1.11640838e-04, 1.23379359e-04, 1.36351780e-04,\n",
       "       1.50687600e-04, 1.66530357e-04, 1.84037955e-04, 2.03385600e-04,\n",
       "       2.24766321e-04, 2.48393306e-04, 2.74502789e-04, 3.03354813e-04,\n",
       "       3.35237681e-04, 3.70468944e-04, 4.09399334e-04, 4.52417444e-04,\n",
       "       4.99951013e-04, 5.52473066e-04, 6.10506453e-04, 6.74626906e-04,\n",
       "       7.45472440e-04, 8.23745097e-04, 9.10221133e-04, 1.00575760e-03,\n",
       "       1.11129810e-03, 1.22788735e-03, 1.35667447e-03, 1.49892876e-03,\n",
       "       1.65605021e-03, 1.82957877e-03, 2.02121865e-03, 2.23284075e-03,\n",
       "       2.46650912e-03, 2.72449665e-03, 3.00930603e-03, 3.32368701e-03,\n",
       "       3.67066660e-03, 4.05357173e-03, 4.47605597e-03, 4.94213449e-03,\n",
       "       5.45620080e-03, 6.02308055e-03, 6.64805667e-03, 7.33690569e-03,\n",
       "       8.09594523e-03, 8.93206056e-03, 9.85276420e-03, 1.08662294e-02,\n",
       "       1.19813355e-02, 1.32077113e-02, 1.45557625e-02, 1.60367284e-02,\n",
       "       1.76627059e-02, 1.94466654e-02, 2.14024857e-02, 2.35449132e-02,\n",
       "       2.58895941e-02, 2.84530222e-02, 3.12524661e-02, 3.43058892e-02,\n",
       "       3.76317725e-02, 4.12490219e-02, 4.51766588e-02, 4.94335666e-02,\n",
       "       5.40381297e-02, 5.90077192e-02, 6.43583015e-02, 7.01037124e-02,\n",
       "       7.62550011e-02, 8.28195885e-02, 8.98003429e-02, 9.71947163e-02,\n",
       "       1.04993582e-01, 1.13180295e-01, 1.21729314e-01, 1.30605757e-01,\n",
       "       1.39763847e-01, 1.49146467e-01, 1.58684939e-01, 1.68298349e-01,\n",
       "       1.77894473e-01, 1.87369928e-01, 1.96611941e-01, 2.05500335e-01,\n",
       "       2.13909686e-01, 2.21712902e-01, 2.28784278e-01, 2.35003710e-01,\n",
       "       2.40260750e-01, 2.44458318e-01, 2.47516587e-01, 2.49376029e-01,\n",
       "       2.50000000e-01, 2.49376029e-01, 2.47516572e-01, 2.44458303e-01,\n",
       "       2.40260720e-01, 2.35003710e-01, 2.28784218e-01, 2.21712887e-01,\n",
       "       2.13909701e-01, 2.05500260e-01, 1.96611956e-01, 1.87369838e-01,\n",
       "       1.77894413e-01, 1.68298334e-01, 1.58684835e-01, 1.49146467e-01,\n",
       "       1.39763758e-01, 1.30605787e-01, 1.21729299e-01, 1.13180213e-01,\n",
       "       1.04993626e-01, 9.71947089e-02, 8.98003057e-02, 8.28195363e-02,\n",
       "       7.62549862e-02, 7.01037124e-02, 6.43582866e-02, 5.90077341e-02,\n",
       "       5.40381111e-02, 4.94335368e-02, 4.51766551e-02, 4.12490331e-02,\n",
       "       3.76317799e-02, 3.43058519e-02, 3.12524140e-02, 2.84530446e-02,\n",
       "       2.58896220e-02, 2.35448945e-02, 2.14025490e-02, 1.94466058e-02,\n",
       "       1.76627338e-02, 1.60367545e-02, 1.45557523e-02, 1.32076964e-02,\n",
       "       1.19813727e-02, 1.08662117e-02, 9.85279121e-03, 8.93211458e-03,\n",
       "       8.09593033e-03, 7.33687775e-03, 6.64803293e-03, 6.02304516e-03,\n",
       "       5.45615098e-03, 4.94218525e-03, 4.47605969e-03, 4.05353727e-03,\n",
       "       3.67064914e-03, 3.32369935e-03, 3.00932792e-03, 2.72445590e-03,\n",
       "       2.46646581e-03, 2.23290781e-03, 2.02120445e-03, 1.82960229e-03,\n",
       "       1.65604567e-03, 1.49894902e-03, 1.35672290e-03, 1.22795347e-03,\n",
       "       1.11128297e-03, 1.00576843e-03, 9.10167466e-04, 8.23712209e-04,\n",
       "       7.45514699e-04, 6.74626499e-04, 6.10574323e-04, 5.52527432e-04,\n",
       "       4.99952002e-04, 4.52492328e-04, 4.09375789e-04, 3.70484311e-04,\n",
       "       3.35223274e-04, 3.03295586e-04, 2.74523190e-04, 2.48430006e-04,\n",
       "       2.24718591e-04, 2.03389267e-04, 1.83965676e-04, 1.66507642e-04,\n",
       "       1.50657841e-04, 1.36356830e-04, 1.23366393e-04, 1.11686626e-04,\n",
       "       1.01079262e-04, 9.14251650e-05, 8.27244003e-05, 7.48578314e-05,\n",
       "       6.77062926e-05, 6.12698204e-05, 5.54292455e-05, 5.01845934e-05,\n",
       "       4.54166766e-05], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.linspace(-10.0, 10.0, 200+1)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)\n",
    "  y = tf.nn.sigmoid(x)\n",
    "\n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None Gradients common mistakes\n",
    "# 1. Tensor instead of Variable\n",
    "# 2. Non-TF calculations (eg. numpy)\n",
    "# 3. Watched variable is non-float (int or string etc)\n",
    "# 4. Variable outside tape context\n",
    "# 5. Some ops do not have gradients (throw error) or are non-differentiable (return None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# To return a zero isntead of None for unconnected grads\n",
    "x= tf.Variable([2., 2.])\n",
    "y = tf.Variable(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  z = y**2\n",
    "print(tape.gradient(z, x, unconnected_gradients=tf.UnconnectedGradients.ZERO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.function returns a tf.types.experimental.PolymorphicFunction\n",
    "# object, which builds a tf graph from a python function\n",
    "# Define a Python function.\n",
    "def a_regular_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# The Python type of `a_function_that_uses_a_graph` will now be a\n",
    "# `PolymorphicFunction`.\n",
    "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
    "\n",
    "# Make some tensors.\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
    "# Call a `tf.function` like a Python function.\n",
    "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
    "assert(orig_value == tf_function_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  print(x)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# Using the `tf.function` decorator makes `outer_function` into a\n",
    "# `PolymorphicFunction`.\n",
    "@tf.function\n",
    "def outer_function(x):\n",
    "  y = tf.constant([[2.0], [3.0]])\n",
    "  b = tf.constant(4.0)\n",
    "\n",
    "  return inner_function(x, y, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the callable will create a graph that\n",
    "# includes `inner_function` as well as `outer_function`.\n",
    "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Automatic conversions inside tf.function\n",
    "**`if` Statements:**\n",
    "1. **Static `if`:** Python boolean, only one branch in the graph.\n",
    "2. **Dynamic `if`:** Tensor condition, converted to `tf.cond` in the graph.\n",
    "\n",
    "**`for` Loops:**\n",
    "1. **Static `for`:** Iterates over a static range, unrolled in the graph.\n",
    "2. **Dynamic `for`:** Tensor range, converted to `tf.while_loop`.\n",
    "\n",
    "**`while` Loops:**\n",
    "1. **Static `while`:** Python condition, resolved during tracing, no loop in the graph.\n",
    "2. **Dynamic `while`:** Tensor condition, converted to `tf.while_loop` in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First branch, with graph: 1\n",
      "Second branch, with graph: 0\n"
     ]
    }
   ],
   "source": [
    "def simple_relu(x):\n",
    "  if tf.greater(x, 0):\n",
    "    return x\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# Using `tf.function` makes `tf_simple_relu` a `PolymorphicFunction` that wraps\n",
    "# `simple_relu`.\n",
    "tf_simple_relu = tf.function(simple_relu)\n",
    "\n",
    "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
    "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__simple_relu(x):\n",
      "    with ag__.FunctionScope('simple_relu', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (do_return, retval_)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal do_return, retval_\n",
      "            do_return, retval_ = vars_\n",
      "\n",
      "        def if_body():\n",
      "            nonlocal do_return, retval_\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = ag__.ld(x)\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "\n",
      "        def else_body():\n",
      "            nonlocal do_return, retval_\n",
      "            try:\n",
      "                do_return = True\n",
      "                retval_ = 0\n",
      "            except:\n",
      "                do_return = False\n",
      "                raise\n",
      "        ag__.if_stmt(ag__.converted_call(ag__.ld(tf).greater, (ag__.ld(x), 0), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the graph-generating output of AutoGraph.\n",
    "print(tf.autograph.to_code(simple_relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  name: \"x\"\n",
      "  op: \"Placeholder\"\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_user_specified_name\"\n",
      "    value {\n",
      "      s: \"x\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater/y\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "        }\n",
      "        int_val: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Greater\"\n",
      "  op: \"Greater\"\n",
      "  input: \"x\"\n",
      "  input: \"Greater/y\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond\"\n",
      "  op: \"StatelessIf\"\n",
      "  input: \"Greater\"\n",
      "  input: \"x\"\n",
      "  attr {\n",
      "    key: \"then_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_true_120\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"output_shapes\"\n",
      "    value {\n",
      "      list {\n",
      "        shape {\n",
      "        }\n",
      "        shape {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"else_branch\"\n",
      "    value {\n",
      "      func {\n",
      "        name: \"cond_false_121\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_read_only_resource_inputs\"\n",
      "    value {\n",
      "      list {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_lower_using_switch_merge\"\n",
      "    value {\n",
      "      b: true\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tout\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_BOOL\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tin\"\n",
      "    value {\n",
      "      list {\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"Tcond\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_BOOL\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"cond/Identity_1\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond:1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"cond/Identity_1\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "versions {\n",
      "  producer: 1882\n",
      "  min_consumer: 12\n",
      "}\n",
      "library {\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_true_120\"\n",
      "      input_arg {\n",
      "        name: \"cond_identity_1_x\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "    attr {\n",
      "      key: \"_construction_context\"\n",
      "      value {\n",
      "        s: \"kEagerRuntime\"\n",
      "      }\n",
      "    }\n",
      "    arg_attr {\n",
      "      key: 0\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_user_specified_name\"\n",
      "          value {\n",
      "            s: \"x\"\n",
      "          }\n",
      "        }\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond_identity_1_x\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "  }\n",
      "  function {\n",
      "    signature {\n",
      "      name: \"cond_false_121\"\n",
      "      input_arg {\n",
      "        name: \"cond_placeholder\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity\"\n",
      "        type: DT_BOOL\n",
      "      }\n",
      "      output_arg {\n",
      "        name: \"cond_identity_1\"\n",
      "        type: DT_INT32\n",
      "      }\n",
      "    }\n",
      "    attr {\n",
      "      key: \"_construction_context\"\n",
      "      value {\n",
      "        s: \"kEagerRuntime\"\n",
      "      }\n",
      "    }\n",
      "    arg_attr {\n",
      "      key: 0\n",
      "      value {\n",
      "        attr {\n",
      "          key: \"_output_shapes\"\n",
      "          value {\n",
      "            list {\n",
      "              shape {\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_1\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_2\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_3\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_BOOL\n",
      "            tensor_shape {\n",
      "            }\n",
      "            bool_val: true\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_3:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_BOOL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Const_4\"\n",
      "      op: \"Const\"\n",
      "      attr {\n",
      "        key: \"value\"\n",
      "        value {\n",
      "          tensor {\n",
      "            dtype: DT_INT32\n",
      "            tensor_shape {\n",
      "            }\n",
      "            int_val: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      attr {\n",
      "        key: \"dtype\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    node_def {\n",
      "      name: \"cond/Identity_1\"\n",
      "      op: \"Identity\"\n",
      "      input: \"cond/Const_4:output:0\"\n",
      "      attr {\n",
      "        key: \"T\"\n",
      "        value {\n",
      "          type: DT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity\"\n",
      "      value: \"cond/Identity:output:0\"\n",
      "    }\n",
      "    ret {\n",
      "      key: \"cond_identity_1\"\n",
      "      value: \"cond/Identity_1:output:0\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the graph itself.\n",
    "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{-1+\\sqrt{17}}{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T03:14:50.177280Z",
     "start_time": "2024-12-15T03:14:50.173513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3511410091698925"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(10 - 2*math.sqrt(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T03:14:55.559398Z",
     "start_time": "2024-12-15T03:14:55.555706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2360679774997898"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(5) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T03:17:19.849381Z",
     "start_time": "2024-12-15T03:17:19.845491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.763819204711734"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*math.sqrt(2*(5+math.sqrt(5))) + math.sqrt(10-2*math.sqrt(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\boxed{\\dfrac{a\\,\\sqrt{3}}{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\[\n",
    "\\boxed{R_{2} = 2r\\,\\bigl(3\\sqrt{3}-5\\bigr) \\quad \\text{and} \\quad \\text{Area}(S_{2}) = 4\\pi\\,r^{2}\\,\\bigl(3\\sqrt{3}-5\\bigr)^{2}}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\[\n",
    "\\frac{R_{2}}{r} = 2\\,(3\\sqrt{3} - 5)\n",
    "\\quad\\text{and}\\quad\n",
    "\\frac{\\text{Area}(S_{2})}{\\text{Area}(S_{1})}\n",
    "= 4\\,(3\\sqrt{3} - 5)^{2}.\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T11:12:29.522788Z",
     "start_time": "2025-01-15T11:12:29.094480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourier Cosine Transform =  sqrt(2)*sqrt(pi)*(1 - w**2)*exp(-w**2/2)/2\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "def fourier_cosine_transform_x2_exp_negx2over2():\n",
    "  x = sp.Symbol('x', real=True, nonnegative=True)\n",
    "  w = sp.Symbol('w', real=True)\n",
    "\n",
    "  # Define the integrand f(x) = x^2 * exp(-x^2/2) * cos(w*x)\n",
    "  f = x**2 * sp.exp(-x**2/sp.Integer(2)) * sp.cos(w*x)\n",
    "\n",
    "  # Perform the integral from 0 to infinity\n",
    "  integral_expr = sp.integrate(f, (x, 0, sp.oo))\n",
    "\n",
    "  # Simplify the result\n",
    "  result = sp.simplify(integral_expr)\n",
    "\n",
    "  return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  result_symbolic = fourier_cosine_transform_x2_exp_negx2over2()\n",
    "  print(\"Fourier Cosine Transform = \", result_symbolic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
